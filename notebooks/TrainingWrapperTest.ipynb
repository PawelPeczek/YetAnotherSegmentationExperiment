{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from src.models.unet import UNet\n",
    "from src.models.icnet import ICNet\n",
    "import src.config as global_config\n",
    "from src.data_access.folds_generation import FoldsGenerator\n",
    "import src.data_access.config as data_access_config\n",
    "from src.evaluation.losses.dice import dice_loss, bce_dice_loss\n",
    "from src.training.training_advision import TrainingAdvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_net = UNet(num_classes=len(global_config.CLASS_MAPPINGS) + 1)\n",
    "ic_net = ICNet(num_classes=len(global_config.CLASS_MAPPINGS) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_genarator = FoldsGenerator(\n",
    "    dataset_path=global_config.DATASET_PATH,\n",
    "    generator_specs=data_access_config.FOLDS_GENERATOR_SPECS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_advisor = TrainingAdvisor.initialize(\n",
    "    output_base_dir=global_config.EXPERIMENTS_OUTPUT_DIR,\n",
    "    input_shape=global_config.MODEL_INPUT_SIZE.to_compact_form() + (3, ),\n",
    "    batch_size=16,\n",
    "    epoch_num=32,\n",
    "    optimizer=\"adam\",\n",
    "    training_set_transformation_chain=data_access_config.TRAINING_TRANSFORMATION_CHAIN,\n",
    "    test_set_transformation_chain=data_access_config.VALIDATION_TRANSFORMATION_CHAIN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Executing training of ic_net on Random split #0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:root:Training set class balance: {'duck': 0.14534883720930233, 'clamp': 0.16666666666666666, 'adapter': 0.22286821705426357, 'drill': 0.21705426356589147, 'box': 0.09302325581395349, 'bottle': 0.15503875968992248}\n",
      "INFO:root:Test set class balance: {'duck': 0.1450381679389313, 'clamp': 0.16793893129770993, 'adapter': 0.22137404580152673, 'drill': 0.21374045801526717, 'box': 0.0916030534351145, 'bottle': 0.16030534351145037}\n",
      "INFO:root:Training will be executed with batch size: 16. Number of epochs: 32. Optimizer: adam.\n",
      "INFO:root:Model saving path: /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "half_x_sub_sampling_conv (Conv2 (None, 64, 64, 16)   448         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "medium_conv_0 (Conv2D)          (None, 64, 64, 64)   9280        half_x_sub_sampling_conv[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "medium_conv_0_bn (BatchNormaliz (None, 64, 64, 64)   256         medium_conv_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "medium_conv_1 (Conv2D)          (None, 64, 64, 64)   36928       medium_conv_0_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "medium_conv_1_bn (BatchNormaliz (None, 64, 64, 64)   256         medium_conv_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "medium_conv_2 (Conv2D)          (None, 64, 64, 64)   36928       medium_conv_1_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "medium_conv_2_bn (BatchNormaliz (None, 64, 64, 64)   256         medium_conv_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "quater_x_sub_sampling_conv (Con (None, 32, 32, 128)  73856       medium_conv_2_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "small_conv_0 (Conv2D)           (None, 32, 32, 128)  147584      quater_x_sub_sampling_conv[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "small_conv_0_bn (BatchNormaliza (None, 32, 32, 128)  512         small_conv_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "small_conv_1 (Conv2D)           (None, 32, 32, 128)  147584      small_conv_0_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "small_conv_1_bn (BatchNormaliza (None, 32, 32, 128)  512         small_conv_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "small_conv_2 (Conv2D)           (None, 32, 32, 256)  295168      small_conv_1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "small_conv_2_bn (BatchNormaliza (None, 32, 32, 256)  1024        small_conv_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "small_branch_up (UpSampling2D)  (None, 64, 64, 256)  0           small_conv_2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "big_conv_0 (Conv2D)             (None, 128, 128, 16) 448         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "small_branch_up_refine (Conv2D) (None, 64, 64, 64)   147520      small_branch_up[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "big_conv_0_bn (BatchNormalizati (None, 128, 128, 16) 64          big_conv_0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "medium_small_fuse_add (Add)     (None, 64, 64, 64)   0           medium_conv_2_bn[0][0]           \n",
      "                                                                 small_branch_up_refine[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "big_conv_1 (Conv2D)             (None, 128, 128, 16) 2320        big_conv_0_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "medium_small_fuse_refine (Conv2 (None, 64, 64, 64)   36928       medium_small_fuse_add[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "big_conv_1_bn (BatchNormalizati (None, 128, 128, 16) 64          big_conv_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "medium_small_fuse_bn (BatchNorm (None, 64, 64, 64)   256         medium_small_fuse_refine[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "big_conv_2 (Conv2D)             (None, 128, 128, 32) 4640        big_conv_1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "medium_branch_up (UpSampling2D) (None, 128, 128, 64) 0           medium_small_fuse_bn[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "big_conv_2_bn (BatchNormalizati (None, 128, 128, 32) 128         big_conv_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "medium_branch_up_refine (Conv2D (None, 128, 128, 32) 18464       medium_branch_up[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "big_medium_fuse_add (Add)       (None, 128, 128, 32) 0           big_conv_2_bn[0][0]              \n",
      "                                                                 medium_branch_up_refine[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "big_medium_fuse_add_bn (BatchNo (None, 128, 128, 32) 128         big_medium_fuse_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "output (Conv2D)                 (None, 128, 128, 7)  231         big_medium_fuse_add_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output_soft_max (Softmax)       (None, 128, 128, 7)  0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 961,783\n",
      "Trainable params: 960,055\n",
      "Non-trainable params: 1,728\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ppeczek/anaconda3/envs/YetAnotherSegmentationExperiment/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "8/8 [==============================] - 2s 274ms/step - loss: 22.1967 - dice_loss: 0.4469\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 22.19674, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 15.6402 - dice_loss: 0.4672 - val_loss: 22.1967 - val_dice_loss: 0.4469\n",
      "Epoch 2/32\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 18.0174 - dice_loss: 0.5480\n",
      "\n",
      "Epoch 00002: val_loss improved from 22.19674 to 18.01745, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 11.3551 - dice_loss: 0.6185 - val_loss: 18.0174 - val_dice_loss: 0.5480\n",
      "Epoch 3/32\n",
      "8/8 [==============================] - 2s 272ms/step - loss: 4.4169 - dice_loss: 0.8755\n",
      "\n",
      "Epoch 00003: val_loss improved from 18.01745 to 4.41687, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 8.4234 - dice_loss: 0.7122 - val_loss: 4.4169 - val_dice_loss: 0.8755\n",
      "Epoch 4/32\n",
      "8/8 [==============================] - 2s 274ms/step - loss: 4.9388 - dice_loss: 0.8973\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.41687\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 6.4371 - dice_loss: 0.7813 - val_loss: 4.9388 - val_dice_loss: 0.8973\n",
      "Epoch 5/32\n",
      "8/8 [==============================] - 2s 261ms/step - loss: 4.9931 - dice_loss: 0.9037\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.41687\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 5.2251 - dice_loss: 0.8213 - val_loss: 4.9931 - val_dice_loss: 0.9037\n",
      "Epoch 6/32\n",
      "8/8 [==============================] - 2s 266ms/step - loss: 4.6618 - dice_loss: 0.9020\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.41687\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 4.5488 - dice_loss: 0.8438 - val_loss: 4.6618 - val_dice_loss: 0.9020\n",
      "Epoch 7/32\n",
      "8/8 [==============================] - 2s 253ms/step - loss: 5.6762 - dice_loss: 0.8918\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.41687\n",
      "32/32 [==============================] - 4s 129ms/step - loss: 3.9198 - dice_loss: 0.8650 - val_loss: 5.6762 - val_dice_loss: 0.8918\n",
      "Epoch 8/32\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 5.4547 - dice_loss: 0.9040\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.41687\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 4.2917 - dice_loss: 0.8450 - val_loss: 5.4547 - val_dice_loss: 0.9040\n",
      "Epoch 9/32\n",
      "8/8 [==============================] - 2s 258ms/step - loss: 4.9850 - dice_loss: 0.9034\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.41687\n",
      "32/32 [==============================] - 4s 129ms/step - loss: 4.0427 - dice_loss: 0.8544 - val_loss: 4.9850 - val_dice_loss: 0.9034\n",
      "Epoch 10/32\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 5.7621 - dice_loss: 0.8843\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.41687\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 3.7183 - dice_loss: 0.8649 - val_loss: 5.7621 - val_dice_loss: 0.8843\n",
      "Epoch 11/32\n",
      "8/8 [==============================] - 2s 266ms/step - loss: 5.4854 - dice_loss: 0.8984\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.41687\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 3.5271 - dice_loss: 0.8740 - val_loss: 5.4854 - val_dice_loss: 0.8984\n",
      "Epoch 12/32\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 4.1119 - dice_loss: 0.9065\n",
      "\n",
      "Epoch 00012: val_loss improved from 4.41687 to 4.11190, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 3.5311 - dice_loss: 0.8741 - val_loss: 4.1119 - val_dice_loss: 0.9065\n",
      "Epoch 13/32\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 3.8730 - dice_loss: 0.9101\n",
      "\n",
      "Epoch 00013: val_loss improved from 4.11190 to 3.87298, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 3.2136 - dice_loss: 0.8854 - val_loss: 3.8730 - val_dice_loss: 0.9101\n",
      "Epoch 14/32\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 3.5170 - dice_loss: 0.9105\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.87298 to 3.51699, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 2.9720 - dice_loss: 0.8946 - val_loss: 3.5170 - val_dice_loss: 0.9105\n",
      "Epoch 15/32\n",
      "8/8 [==============================] - 2s 265ms/step - loss: 3.6240 - dice_loss: 0.9093\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.51699\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 2.9014 - dice_loss: 0.8967 - val_loss: 3.6240 - val_dice_loss: 0.9093\n",
      "Epoch 16/32\n",
      "8/8 [==============================] - 2s 276ms/step - loss: 2.6332 - dice_loss: 0.9206\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.51699 to 2.63323, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 2.9932 - dice_loss: 0.8949 - val_loss: 2.6332 - val_dice_loss: 0.9206\n",
      "Epoch 17/32\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 2.1254 - dice_loss: 0.9291\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.63323 to 2.12543, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 2.9393 - dice_loss: 0.8969 - val_loss: 2.1254 - val_dice_loss: 0.9291\n",
      "Epoch 18/32\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 1.9848 - dice_loss: 0.9337\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.12543 to 1.98479, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 2.6978 - dice_loss: 0.9046 - val_loss: 1.9848 - val_dice_loss: 0.9337\n",
      "Epoch 19/32\n",
      "8/8 [==============================] - 2s 265ms/step - loss: 1.5430 - dice_loss: 0.9403\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.98479 to 1.54296, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 2.8040 - dice_loss: 0.9026 - val_loss: 1.5430 - val_dice_loss: 0.9403\n",
      "Epoch 20/32\n",
      "8/8 [==============================] - 2s 283ms/step - loss: 1.8694 - dice_loss: 0.9379\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.54296\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 2.6287 - dice_loss: 0.9067 - val_loss: 1.8694 - val_dice_loss: 0.9379\n",
      "Epoch 21/32\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 2.9195 - dice_loss: 0.9169\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.54296\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 2.8079 - dice_loss: 0.9016 - val_loss: 2.9195 - val_dice_loss: 0.9169\n",
      "Epoch 22/32\n",
      "8/8 [==============================] - 2s 265ms/step - loss: 1.3145 - dice_loss: 0.9459\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.54296 to 1.31452, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 2.5574 - dice_loss: 0.9110 - val_loss: 1.3145 - val_dice_loss: 0.9459\n",
      "Epoch 23/32\n",
      "8/8 [==============================] - 2s 285ms/step - loss: 1.3952 - dice_loss: 0.9428\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.31452\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 2.4410 - dice_loss: 0.9135 - val_loss: 1.3952 - val_dice_loss: 0.9428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/32\n",
      "8/8 [==============================] - 2s 265ms/step - loss: 1.3450 - dice_loss: 0.9475\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.31452\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 2.3413 - dice_loss: 0.9179 - val_loss: 1.3450 - val_dice_loss: 0.9475\n",
      "Epoch 25/32\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 1.4780 - dice_loss: 0.9422\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.31452\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 2.4666 - dice_loss: 0.9119 - val_loss: 1.4780 - val_dice_loss: 0.9422\n",
      "Epoch 26/32\n",
      "8/8 [==============================] - 2s 290ms/step - loss: 1.3422 - dice_loss: 0.9446\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.31452\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 2.3753 - dice_loss: 0.9175 - val_loss: 1.3422 - val_dice_loss: 0.9446\n",
      "Epoch 27/32\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 1.2532 - dice_loss: 0.9476\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.31452 to 1.25319, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 2.1690 - dice_loss: 0.9237 - val_loss: 1.2532 - val_dice_loss: 0.9476\n",
      "Epoch 28/32\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 1.4539 - dice_loss: 0.9421\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.25319\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 2.3144 - dice_loss: 0.9188 - val_loss: 1.4539 - val_dice_loss: 0.9421\n",
      "Epoch 29/32\n",
      "8/8 [==============================] - 2s 273ms/step - loss: 1.1228 - dice_loss: 0.9528\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.25319 to 1.12281, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 2.0499 - dice_loss: 0.9281 - val_loss: 1.1228 - val_dice_loss: 0.9528\n",
      "Epoch 30/32\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 1.3342 - dice_loss: 0.9440\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.12281\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 2.2289 - dice_loss: 0.9214 - val_loss: 1.3342 - val_dice_loss: 0.9440\n",
      "Epoch 31/32\n",
      "8/8 [==============================] - 2s 268ms/step - loss: 1.5090 - dice_loss: 0.9358\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.12281\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 2.1637 - dice_loss: 0.9244 - val_loss: 1.5090 - val_dice_loss: 0.9358\n",
      "Epoch 32/32\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 0.8950 - dice_loss: 0.9638\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.12281 to 0.89499, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/ic_net/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 2.0418 - dice_loss: 0.9281 - val_loss: 0.8950 - val_dice_loss: 0.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training history: {'loss': [15.640178114175797, 11.355125784873962, 8.423440769314766, 6.437142550945282, 5.2250655591487885, 4.548820771276951, 3.9197653755545616, 4.291723392903805, 4.042659379541874, 3.7182574570178986, 3.5271316915750504, 3.5311494544148445, 3.2136265262961388, 2.9719763435423374, 2.9014446288347244, 2.9931730777025223, 2.939303755760193, 2.6978008039295673, 2.8039668910205364, 2.6287264563143253, 2.807948485016823, 2.5574055425822735, 2.441049315035343, 2.3413017205893993, 2.4665782935917377, 2.375272024422884, 2.168968576937914, 2.3144217543303967, 2.0498797558248043, 2.2289343364536762, 2.1636552214622498, 2.0417913533747196], 'dice_loss': [0.46718925, 0.61853546, 0.7122264, 0.78128856, 0.8212731, 0.8438175, 0.8649532, 0.84504783, 0.8544194, 0.8649203, 0.87398094, 0.874135, 0.8853668, 0.89461416, 0.89673966, 0.89490724, 0.8968593, 0.90463006, 0.90264493, 0.90673804, 0.901618, 0.91101253, 0.9135224, 0.917905, 0.91185015, 0.9175451, 0.923671, 0.9188116, 0.92808026, 0.92143196, 0.924443, 0.92810345], 'val_loss': [22.196736812591553, 18.01744794845581, 4.416873395442963, 4.9387728571891785, 4.993105113506317, 4.661817729473114, 5.676249027252197, 5.454696178436279, 4.984950363636017, 5.762132227420807, 5.485442936420441, 4.111899048089981, 3.872978538274765, 3.516987055540085, 3.624002367258072, 2.633231908082962, 2.1254322081804276, 1.984787330031395, 1.5429593473672867, 1.8693601191043854, 2.9194994270801544, 1.3145189434289932, 1.3951746821403503, 1.3449937254190445, 1.478020653128624, 1.3421698063611984, 1.2531923949718475, 1.4538806527853012, 1.1228118985891342, 1.3341788053512573, 1.5090443938970566, 0.8949875012040138], 'val_dice_loss': [0.44686154, 0.5480077, 0.87553996, 0.8973218, 0.903719, 0.9020348, 0.8917826, 0.9039505, 0.9033989, 0.88433385, 0.89837664, 0.9064905, 0.9101119, 0.9105054, 0.90926015, 0.92057884, 0.92913103, 0.9337182, 0.94031787, 0.93790567, 0.916906, 0.9458715, 0.9428367, 0.9475045, 0.9421996, 0.9445941, 0.9475673, 0.94207275, 0.95284766, 0.943982, 0.93584794, 0.96381843]}\n",
      "INFO:root:Model removed from memory.\n",
      "INFO:root:Training finished.\n",
      "INFO:root:Executing training of u_net_original on Random split #0...\n",
      "INFO:root:Training set class balance: {'duck': 0.14534883720930233, 'clamp': 0.16666666666666666, 'adapter': 0.22286821705426357, 'drill': 0.21705426356589147, 'box': 0.09302325581395349, 'bottle': 0.15503875968992248}\n",
      "INFO:root:Test set class balance: {'duck': 0.1450381679389313, 'clamp': 0.16793893129770993, 'adapter': 0.22137404580152673, 'drill': 0.21374045801526717, 'box': 0.0916030534351145, 'bottle': 0.16030534351145037}\n",
      "INFO:root:Training will be executed with batch size: 16. Number of epochs: 32. Optimizer: adam.\n",
      "INFO:root:Model saving path: /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/u_net_original/random_split_#0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_1_1 (Conv2D)          (None, 128, 128, 64) 1792        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_1_2 (Conv2D)          (None, 128, 128, 64) 36928       sub_stack_1_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_1_3 (Conv2D)          (None, 128, 128, 64) 36928       sub_stack_1_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_1_bn (BatchNormalizat (None, 128, 128, 64) 256         sub_stack_1_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_2_input (MaxPooling2D (None, 64, 64, 64)   0           sub_stack_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_2_1 (Conv2D)          (None, 64, 64, 128)  73856       sub_stack_2_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_2_2 (Conv2D)          (None, 64, 64, 128)  147584      sub_stack_2_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_2_3 (Conv2D)          (None, 64, 64, 128)  147584      sub_stack_2_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_2_bn (BatchNormalizat (None, 64, 64, 128)  512         sub_stack_2_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_3_input (MaxPooling2D (None, 32, 32, 128)  0           sub_stack_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_3_1 (Conv2D)          (None, 32, 32, 256)  295168      sub_stack_3_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_3_2 (Conv2D)          (None, 32, 32, 256)  590080      sub_stack_3_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_3_3 (Conv2D)          (None, 32, 32, 256)  590080      sub_stack_3_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_3_bn (BatchNormalizat (None, 32, 32, 256)  1024        sub_stack_3_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_4_input (MaxPooling2D (None, 16, 16, 256)  0           sub_stack_3_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_4_1 (Conv2D)          (None, 16, 16, 512)  1180160     sub_stack_4_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_4_2 (Conv2D)          (None, 16, 16, 512)  2359808     sub_stack_4_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_4_3 (Conv2D)          (None, 16, 16, 512)  2359808     sub_stack_4_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_4_bn (BatchNormalizat (None, 16, 16, 512)  2048        sub_stack_4_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sub_stack_5_input (MaxPooling2D (None, 8, 8, 512)    0           sub_stack_4_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "filter_extraction_conv (Conv2D) (None, 8, 8, 1024)   4719616     sub_stack_5_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "filter_extraction_conv_bn (Batc (None, 8, 8, 1024)   4096        filter_extraction_conv[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling_input (Conv2D)      (None, 8, 8, 512)    4719104     filter_extraction_conv_bn[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 16, 16, 512)  0           up_sampling_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_bottleneck_conv_1 (Co (None, 16, 16, 256)  524544      up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_concat_1 (Concatenate (None, 16, 16, 768)  0           up_sample_bottleneck_conv_1[0][0]\n",
      "                                                                 sub_stack_4_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_1_conv_3x3_1 (Conv2D) (None, 16, 16, 384)  2654592     up_sample_concat_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_1_conv_3x3_2 (Conv2D) (None, 16, 16, 384)  1327488     up_sample_1_conv_3x3_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_1_bn (BatchNormalizat (None, 16, 16, 384)  1536        up_sample_1_conv_3x3_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 384)  0           up_sample_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_bottleneck_conv_2 (Co (None, 32, 32, 192)  295104      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_concat_2 (Concatenate (None, 32, 32, 448)  0           up_sample_bottleneck_conv_2[0][0]\n",
      "                                                                 sub_stack_3_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_2_conv_3x3_1 (Conv2D) (None, 32, 32, 224)  903392      up_sample_concat_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_2_conv_3x3_2 (Conv2D) (None, 32, 32, 224)  451808      up_sample_2_conv_3x3_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_2_bn (BatchNormalizat (None, 32, 32, 224)  896         up_sample_2_conv_3x3_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 224)  0           up_sample_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_bottleneck_conv_3 (Co (None, 64, 64, 112)  100464      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_concat_3 (Concatenate (None, 64, 64, 240)  0           up_sample_bottleneck_conv_3[0][0]\n",
      "                                                                 sub_stack_2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_3_conv_3x3_1 (Conv2D) (None, 64, 64, 120)  259320      up_sample_concat_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_3_conv_3x3_2 (Conv2D) (None, 64, 64, 120)  129720      up_sample_3_conv_3x3_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_3_bn (BatchNormalizat (None, 64, 64, 120)  480         up_sample_3_conv_3x3_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 120 0           up_sample_3_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_bottleneck_conv_4 (Co (None, 128, 128, 60) 28860       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_concat_4 (Concatenate (None, 128, 128, 124 0           up_sample_bottleneck_conv_4[0][0]\n",
      "                                                                 sub_stack_1_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_4_conv_3x3_1 (Conv2D) (None, 128, 128, 62) 69254       up_sample_concat_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_4_conv_3x3_2 (Conv2D) (None, 128, 128, 62) 34658       up_sample_4_conv_3x3_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sample_4_bn (BatchNormalizat (None, 128, 128, 62) 248         up_sample_4_conv_3x3_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "output (Conv2D)                 (None, 128, 128, 7)  441         up_sample_4_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_soft_max (Softmax)       (None, 128, 128, 7)  0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 24,049,237\n",
      "Trainable params: 24,043,689\n",
      "Non-trainable params: 5,548\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "8/8 [==============================] - 2s 291ms/step - loss: 16.9184 - dice_loss: 0.6584\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 16.91835, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/u_net_original/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 13s 421ms/step - loss: 10.8097 - dice_loss: 0.6274 - val_loss: 16.9184 - val_dice_loss: 0.6584\n",
      "Epoch 2/32\n",
      "8/8 [==============================] - 2s 263ms/step - loss: 17.3861 - dice_loss: 0.6366\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 16.91835\n",
      "32/32 [==============================] - 8s 259ms/step - loss: 5.4411 - dice_loss: 0.8106 - val_loss: 17.3861 - val_dice_loss: 0.6366\n",
      "Epoch 3/32\n",
      "8/8 [==============================] - 2s 262ms/step - loss: 4.3283 - dice_loss: 0.8640\n",
      "\n",
      "Epoch 00003: val_loss improved from 16.91835 to 4.32831, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/u_net_original/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 4.3067 - dice_loss: 0.8558 - val_loss: 4.3283 - val_dice_loss: 0.8640\n",
      "Epoch 4/32\n",
      "8/8 [==============================] - 2s 267ms/step - loss: 2.8106 - dice_loss: 0.9101\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.32831 to 2.81061, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/u_net_original/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 9s 276ms/step - loss: 3.7574 - dice_loss: 0.8726 - val_loss: 2.8106 - val_dice_loss: 0.9101\n",
      "Epoch 5/32\n",
      "8/8 [==============================] - 2s 288ms/step - loss: 2.8461 - dice_loss: 0.9229\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.81061\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 3.2067 - dice_loss: 0.8942 - val_loss: 2.8461 - val_dice_loss: 0.9229\n",
      "Epoch 6/32\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 2.5408 - dice_loss: 0.9308\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.81061 to 2.54077, saving model to /home/ppeczek/Dokumenty/YetAnotherSegmentationExperiment/resources/experiments/test_experiment_v1/u_net_original/random_split_#0/weights.hdf5\n",
      "32/32 [==============================] - 8s 259ms/step - loss: 3.0647 - dice_loss: 0.8974 - val_loss: 2.5408 - val_dice_loss: 0.9308\n",
      "Epoch 7/32\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 3.3175 - dice_loss: 0.9036\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.54077\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 2.9391 - dice_loss: 0.9024 - val_loss: 3.3175 - val_dice_loss: 0.9036\n",
      "Epoch 8/32\n",
      "13/32 [===========>..................] - ETA: 3s - loss: 2.8527 - dice_loss: 0.9069"
     ]
    }
   ],
   "source": [
    "training_advisor.execute_training(\n",
    "    experiment_name=\"test_experiment_v1\",\n",
    "    folds_generator=folds_genarator,\n",
    "    models_to_train=[(\"ic_net\", ic_net), (\"u_net_original\", u_net)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YetAnotherSegmentationExperiment",
   "language": "python",
   "name": "yetanothersegmentationexperiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
